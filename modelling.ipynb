{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import random\n",
    "# import json\n",
    "# import re\n",
    "import pickle\n",
    "\n",
    "# vizu\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# modelling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn import svm\n",
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrandom = 42\n",
    "np.random.seed(myrandom)\n",
    "mu, sigma = 0, 1\n",
    "feature_fake = np.random.normal(mu, sigma, 200)+2\n",
    "target_fake = np.random.normal(mu, sigma, 200)*2\n",
    "df = pd.DataFrame({'weight': feature_fake, 'price': target_fake})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joinded_scaled = gf.scale(joined[[kpi] + comp_raw], _min = 0, _max=1)\n",
    "\n",
    "# scaler = StandardScaler().fit(df)\n",
    "# df = pd.DataFrame(scaler.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='weight', y='price', style='o')\n",
    "plt.title('weight vs weight')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['weight']\n",
    "target = 'price'\n",
    "data_train, data_test, target_train, target_test = train_test_split(df[predictors], df[target], test_size=0.25, \n",
    "                                                                    random_state=myrandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=100, max_depth=3, random_state=myrandom)\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame({'Actual': target_test, 'Predicted': y_pred})\n",
    "error_df.plot(x='Actual', y='Predicted', style='o')\n",
    "# plt.title('weight vs weight')\n",
    "# plt.xlabel('weight')\n",
    "# plt.ylabel('price')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gyujtsed valahova a modellek eredmenyet!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(target_test, y_pred))\n",
    "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(target_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(target_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = imp_df(X_train.columns, perm.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), \n",
    "                                                                                             rf.oob_score_,\n",
    "                                                                                             rf.score(X_valid, y_valid)))\n",
    "\n",
    "                                                                                             from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance (logit)\n",
    "\n",
    "# print(model.intercept_)\n",
    "# print(model.coef_)\n",
    "\n",
    "logit = LogisticRegression(random_state=random_st, solver='lbfgs').fit(data_train, target_train)\n",
    "\n",
    "def get_coefs_bar(fitted_clf, predictors, translator = None):\n",
    "    imp_df = pd.DataFrame(fitted_clf.coef_)\n",
    "\n",
    "    imp_df = imp_df.T\n",
    "    imp_df['predictors'] = predictors\n",
    "    if translator is not None:\n",
    "        imp_df['predictors'] = pd.Series(predictors).replace(translator).replace({' ': '_'}, regex=True)\n",
    "\n",
    "    imp_df = imp_df.set_index('predictors')\n",
    "    ax = imp_df.plot.barh()\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "get_coefs_bar(logit, predictors = predictors, translator = translat_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp = {}\n",
    "for var,weight in zip(data_train.columns, model.feature_importances_):\n",
    "    varimp[var] = weight\n",
    "pd.DataFrame({'varimp': varimp}).sort_values('varimp').plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance (XGBoost)\n",
    "model = str(best)\n",
    "pars = {}\n",
    "model = best\n",
    "mlf.get_shap_summary_plot(data_train, target_train, data_test, model, pars)\n",
    "mlf.get_shap_force_plot(data_train, target_train, data_test, model, pars)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
