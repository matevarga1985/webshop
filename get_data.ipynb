{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselink = \"https://www.aekszerek.hu/arany/noi-arany-nyaklancok.html?lis=\"\n",
    "n_of_pages=4\n",
    "urls_for_items = [] # e.g.\"https://www.aekszerek.hu/ezust/nyaklancok/noi/ezust-nyaklanc-sziv-p156367.html\",\n",
    "\n",
    "for page in range(n_of_pages):\n",
    "    source = requests.get(baselink + str(page)).content\n",
    "    soupbase = BeautifulSoup(source, \"html.parser\")\n",
    "\n",
    "    item_imgs_on_this_page = soupbase.find_all('div', class_=\"item_img\")\n",
    "    urls_for_items_on_this_page = [\"https://www.aekszerek.hu/\" + item.a['href'] for item in item_imgs_on_this_page]\n",
    "\n",
    "    urls_for_items = urls_for_items + urls_for_items_on_this_page\n",
    "\n",
    "print(f\"{len(urls_for_items)} item-url is found after going through {n_of_pages} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_for_item(soup):\n",
    "    pricevalue_in_string = soup.find('span', id=\"pricevalue\").text # '\\n56 510 Ft \\n'\n",
    "    numbers_in_pricevalue = [s for s in pricevalue_in_string.split() if s.isdigit()] # [56, 510]\n",
    "    price_in_int = int(''.join((numbers_in_pricevalue)))\n",
    "    return price_in_int\n",
    "\n",
    "def get_itemdetails_for_item(soup):\n",
    "    item_details_with_noise = soup.find('div', class_='col-md-8 col-sm-12 col-xs-12 margin-bottom10 toggle-content')\n",
    "    item_details_in_string = item_details_with_noise.find('div', class_='margin-bottom10').text\n",
    "\n",
    "    details = [\"Anyag\", \"Nyaklánc kapocs\", \"Motívum\", \"Célcsoport\", \"Ékszer súlya\", \"Tisztaság\", \"Arany színe\", \"Hossz\", \"Szélesség\", \"Magasság\", \"Kő\"]\n",
    "    item_details_dict = {}\n",
    "    for detail in details:\n",
    "        try:\n",
    "            value = item_details_in_string.split(f'\\n{detail}: ')[1].split(',\\n')[0]\n",
    "            item_details_dict[detail] = value\n",
    "        except:\n",
    "            item_details_dict[detail] = None\n",
    "\n",
    "    return item_details_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2p alatt 65ig\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, itemurl in enumerate(urls_for_items):\n",
    "    if i%10 == 0:\n",
    "        print(f\"{i} out of {len(urls_for_items)}\")\n",
    "    soup = BeautifulSoup(requests.get(itemurl).content, \"html.parser\")\n",
    "    item_title = soup.title.text\n",
    "    price = get_price_for_item(soup)\n",
    "    itemdetails = get_itemdetails_for_item(soup)\n",
    "    \n",
    "    # df = df.append(pd.Series(dict({'price': price, 'url': itemurl, 'title':item_title, **itemdetails})), ignore_index=True)\n",
    "    df = pd.concat([df, pd.Series(dict({'price': price, 'url': itemurl, 'title':item_title, **itemdetails}))], axis=1)\n",
    "df = df.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nyaklanc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d06dc2b3c886f11aa8cc8b4f512d81e7036453e0e479b76a08dae5bce600d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
